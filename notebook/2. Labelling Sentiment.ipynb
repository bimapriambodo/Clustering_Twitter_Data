{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import TFAutoModelForSequenceClassification\n",
    "from transformers import AutoTokenizer, AutoConfig\n",
    "from scipy.special import softmax\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"../data/tweets.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>content</th>\n",
       "      <th>username</th>\n",
       "      <th>tweet_url</th>\n",
       "      <th>reply_count</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>like_count</th>\n",
       "      <th>verified</th>\n",
       "      <th>followers</th>\n",
       "      <th>content_clean</th>\n",
       "      <th>content_translated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-04-08 15:01:24+00:00</td>\n",
       "      <td>Dr  Piutang THR\\nDr  Piutang Gaji\\n    Cr  Pen...</td>\n",
       "      <td>txtdrakuntansi</td>\n",
       "      <td>https://twitter.com/txtdrakuntansi/status/1644...</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>False</td>\n",
       "      <td>59697</td>\n",
       "      <td>dr piutang thr dr piutang gaji cr pendapatan j...</td>\n",
       "      <td>from the receivables of the THR receivables fr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-04-08 14:52:40+00:00</td>\n",
       "      <td>@islabellecoco @gojekindonesia Sedikit curhat ...</td>\n",
       "      <td>gummypark61</td>\n",
       "      <td>https://twitter.com/gummypark61/status/1644714...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>14</td>\n",
       "      <td>sedikit curhat bahkan pas korona aja pernah ma...</td>\n",
       "      <td>a little vent even when corona just entered fu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-04-08 14:45:03+00:00</td>\n",
       "      <td>rep dibawah sini yg mau spay thr receh 1.000 u...</td>\n",
       "      <td>yufada_</td>\n",
       "      <td>https://twitter.com/yufada_/status/16447129669...</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>113</td>\n",
       "      <td>rep dibawah sini yg mau spay thr receh 1000 un...</td>\n",
       "      <td>Rep below are those who want to spay THR DREH ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-04-08 13:39:44+00:00</td>\n",
       "      <td>Selamat kepada :\\n@emirahay82\\n@0M_YANT0\\n@Mis...</td>\n",
       "      <td>mindaart</td>\n",
       "      <td>https://twitter.com/mindaart/status/1644696530...</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>1551</td>\n",
       "      <td>selamat kepada pemenang ga thr masing2 100 spa...</td>\n",
       "      <td>Congratulations to the winner of GA THR each 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-04-08 12:51:00+00:00</td>\n",
       "      <td>ak supres pake link thr sama daget yh yg ke 4</td>\n",
       "      <td>haelovelychan</td>\n",
       "      <td>https://twitter.com/haelovelychan/status/16446...</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>35</td>\n",
       "      <td>False</td>\n",
       "      <td>57379</td>\n",
       "      <td>ak supres pake link thr sama daget yh yg ke 4</td>\n",
       "      <td>A suppress packed link</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        date   \n",
       "0  2023-04-08 15:01:24+00:00  \\\n",
       "1  2023-04-08 14:52:40+00:00   \n",
       "2  2023-04-08 14:45:03+00:00   \n",
       "3  2023-04-08 13:39:44+00:00   \n",
       "4  2023-04-08 12:51:00+00:00   \n",
       "\n",
       "                                             content        username   \n",
       "0  Dr  Piutang THR\\nDr  Piutang Gaji\\n    Cr  Pen...  txtdrakuntansi  \\\n",
       "1  @islabellecoco @gojekindonesia Sedikit curhat ...     gummypark61   \n",
       "2  rep dibawah sini yg mau spay thr receh 1.000 u...         yufada_   \n",
       "3  Selamat kepada :\\n@emirahay82\\n@0M_YANT0\\n@Mis...        mindaart   \n",
       "4      ak supres pake link thr sama daget yh yg ke 4   haelovelychan   \n",
       "\n",
       "                                           tweet_url  reply_count   \n",
       "0  https://twitter.com/txtdrakuntansi/status/1644...            1  \\\n",
       "1  https://twitter.com/gummypark61/status/1644714...            1   \n",
       "2  https://twitter.com/yufada_/status/16447129669...           26   \n",
       "3  https://twitter.com/mindaart/status/1644696530...           12   \n",
       "4  https://twitter.com/haelovelychan/status/16446...           18   \n",
       "\n",
       "   retweet_count  like_count  verified  followers   \n",
       "0              6          11     False      59697  \\\n",
       "1              1           1     False         14   \n",
       "2              1           1     False        113   \n",
       "3              1           5     False       1551   \n",
       "4              2          35     False      57379   \n",
       "\n",
       "                                       content_clean   \n",
       "0  dr piutang thr dr piutang gaji cr pendapatan j...  \\\n",
       "1  sedikit curhat bahkan pas korona aja pernah ma...   \n",
       "2  rep dibawah sini yg mau spay thr receh 1000 un...   \n",
       "3  selamat kepada pemenang ga thr masing2 100 spa...   \n",
       "4      ak supres pake link thr sama daget yh yg ke 4   \n",
       "\n",
       "                                  content_translated  \n",
       "0  from the receivables of the THR receivables fr...  \n",
       "1  a little vent even when corona just entered fu...  \n",
       "2  Rep below are those who want to spay THR DREH ...  \n",
       "3  Congratulations to the winner of GA THR each 1...  \n",
       "4                             A suppress packed link  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading (…)olve/main/vocab.json: 100%|██████████| 899k/899k [00:00<00:00, 1.31MB/s]\n",
      "Downloading (…)olve/main/merges.txt: 100%|██████████| 456k/456k [00:00<00:00, 1.26MB/s]\n",
      "Downloading (…)cial_tokens_map.json: 100%|██████████| 150/150 [00:00<00:00, 36.0kB/s]\n",
      "Downloading (…)lve/main/config.json: 100%|██████████| 747/747 [00:00<00:00, 206kB/s]\n",
      "Downloading pytorch_model.bin: 100%|██████████| 499M/499M [02:10<00:00, 3.83MB/s] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RobertaForSequenceClassification(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): RobertaClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=3, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification\n",
    "\n",
    "tokenizer = RobertaTokenizer.from_pretrained('cardiffnlp/twitter-roberta-base-sentiment')\n",
    "model = RobertaForSequenceClassification.from_pretrained('cardiffnlp/twitter-roberta-base-sentiment')\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def predict_sentiment(model, tokenizer, text):\n",
    "    # Tokenisasi teks dan tambahkan token khusus untuk awal dan akhir kalimat\n",
    "    inputs = tokenizer.encode_plus(text, add_special_tokens=True, return_tensors='pt')\n",
    "    \n",
    "    # Mengambil input di dalam dictionary 'inputs'\n",
    "    input_ids = inputs['input_ids']\n",
    "    attention_mask = inputs['attention_mask']\n",
    "    \n",
    "    # Beri tahu model bahwa tidak perlu melakukan perhitungan gradien\n",
    "    with torch.no_grad():\n",
    "        # Inferensi model untuk memperoleh output probabilitas kelas\n",
    "        outputs = model(input_ids, attention_mask)\n",
    "        logits = outputs.logits\n",
    "    \n",
    "    # Menerapkan argmax() pada dimensi kedua (dimensi dengan indeks 1) pada tensor logits\n",
    "    predicted_class_idx = torch.argmax(logits, dim=1).item()\n",
    "\n",
    "    if predicted_class_idx == 0:\n",
    "        return \"negative\"\n",
    "    elif predicted_class_idx == 1:\n",
    "        return \"neutral\"\n",
    "    else:\n",
    "        return \"positive\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Membuat list untuk menyimpan hasil prediksi sentimen tiap tweet\n",
    "sentiments = []\n",
    "\n",
    "# Iterasi untuk setiap tweet dalam kolom 'tweets' di dalam pandas DataFrame df\n",
    "for tweet in df['content_translated']:\n",
    "    # Memanggil fungsi predict_sentiment() untuk memprediksi sentimen dari teks\n",
    "    sentiment = predict_sentiment(model, tokenizer, tweet)\n",
    "    sentiments.append(sentiment)\n",
    "\n",
    "# Tambahkan kolom baru 'sentiment' ke dalam DataFrame\n",
    "df['sentiment'] = sentiments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['date', 'content', 'username', 'tweet_url', 'reply_count',\n",
       "       'retweet_count', 'like_count', 'verified', 'followers', 'content_clean',\n",
       "       'content_translated', 'sentiment'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content_translated</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>from the receivables of the THR receivables fr...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a little vent even when corona just entered fu...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rep below are those who want to spay THR DREH ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Congratulations to the winner of GA THR each 1...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A suppress packed link</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  content_translated sentiment\n",
       "0  from the receivables of the THR receivables fr...   neutral\n",
       "1  a little vent even when corona just entered fu...   neutral\n",
       "2  Rep below are those who want to spay THR DREH ...  negative\n",
       "3  Congratulations to the winner of GA THR each 1...  positive\n",
       "4                             A suppress packed link   neutral"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['content_translated', 'sentiment']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "neutral     126\n",
       "negative     42\n",
       "positive     32\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['date', 'content', 'username', 'tweet_url', 'reply_count',\n",
       "       'retweet_count', 'like_count', 'verified', 'followers', 'content_clean',\n",
       "       'content_translated', 'sentiment'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "df[['date',\n",
    "'username',\n",
    "'content_clean',\n",
    "'content_translated',\n",
    "'sentiment']].to_csv(r\"../data/processed/tweets_label.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlpenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
